import { TextToSpeechClient } from '@google-cloud/text-to-speech';
import fs from 'fs/promises';
import path from 'path';

export interface TTSOptions {
  text: string;
  outputPath: string;
  voice?: string;
  speed?: number;
  pitch?: number;
}

export class TextToSpeechService {
  private client: TextToSpeechClient;

  constructor() {
    try {
      // Initialize Google Cloud TTS client with proper credential handling
      const credentialsPath = process.env.GOOGLE_APPLICATION_CREDENTIALS || process.env.GOOGLE_CREDENTIALS || './google-credentials.json';

      // Try to read credentials directly from file
      let credentials = null;
      try {
        const fs = require('fs');
        if (fs.existsSync(credentialsPath)) {
          credentials = JSON.parse(fs.readFileSync(credentialsPath, 'utf8'));
        }
      } catch (e) {
        console.warn('Could not read credentials file, trying environment variable');
      }

      // Initialize with credentials object or keyFilename
      if (credentials) {
        this.client = new TextToSpeechClient({
          credentials: credentials,
          projectId: credentials.project_id || process.env.GOOGLE_CLOUD_PROJECT_ID || 'magnetic-racer-442915-u4'
        });
      } else {
        this.client = new TextToSpeechClient({
          keyFilename: credentialsPath,
          projectId: process.env.GOOGLE_CLOUD_PROJECT_ID || 'magnetic-racer-442915-u4'
        });
      }

      console.log('‚úÖ Google Cloud TTS client initialized');
    } catch (error) {
      console.error('‚ùå Failed to initialize Google Cloud TTS client:', error);
      throw new Error(`TTS client initialization failed: ${error.message}`);
    }
  }

  async generateSpeech(options: TTSOptions): Promise<string> {
    try {
      const { text, outputPath, voice = 'en-IN-Wavenet-D', speed = 1.0, pitch = 0 } = options;

      // First, try Google Cloud TTS
      try {
        // Configure the synthesis request
        const request = {
          input: { text },
          voice: {
            languageCode: 'en-IN',
            name: voice,
            ssmlGender: voice.includes('D') || voice.includes('B') ? 'MALE' : 'FEMALE' as const,
          },
          audioConfig: {
            audioEncoding: 'MP3' as const,
            speakingRate: speed,
            pitch: pitch,
            volumeGainDb: 0,
            sampleRateHertz: 22050,
          },
        };

        console.log(`üé§ Generating speech with Google Cloud TTS - voice: ${voice}`);

        // Perform the text-to-speech request
        const [response] = await this.client.synthesizeSpeech(request);

        if (!response.audioContent) {
          throw new Error('No audio content received from Google TTS');
        }

        // Ensure output directory exists
        const outputDir = path.dirname(outputPath);
        await fs.mkdir(outputDir, { recursive: true });

        // Write the audio content to file
        await fs.writeFile(outputPath, response.audioContent as Buffer);

        console.log(`‚úÖ Audio saved to: ${outputPath}`);
        return outputPath;

      } catch (googleError) {
        console.warn('‚ö†Ô∏è Google Cloud TTS failed, using fallback method:', googleError.message);
        return await this.generateFallbackAudio(text, outputPath);
      }

    } catch (error) {
      console.error('‚ùå Text-to-speech generation failed:', error);
      throw new Error(`TTS generation failed: ${error.message}`);
    }
  }

  private async generateFallbackAudio(text: string, outputPath: string): Promise<string> {
    try {
      console.log('üîÑ Generating fallback audio content...');

      // Ensure output directory exists
      const outputDir = path.dirname(outputPath);
      await fs.mkdir(outputDir, { recursive: true });

      // Try to use system TTS commands
      try {
        const { execSync } = await import('child_process');
        const fs = await import('fs');

        // Try espeak first (common on Linux)
        try {
          const wavPath = outputPath.replace('.mp3', '.wav');
          execSync.execSync(`espeak "${text.substring(0, 500)}" -w "${wavPath}"`, { stdio: 'pipe' });

          // Convert to mp3 if ffmpeg is available
          try {
            execSync.execSync(`ffmpeg -i "${wavPath}" "${outputPath}" -y`, { stdio: 'pipe' });
            execSync.execSync(`rm "${wavPath}"`, { stdio: 'pipe' });
          } catch {
            // If ffmpeg fails, just rename wav to mp3
            execSync.execSync(`mv "${wavPath}" "${outputPath}"`, { stdio: 'pipe' });
          }

          console.log(`üì± System TTS audio created: ${outputPath}`);
          return outputPath;
        } catch (espeakError) {
          console.warn('espeak not available, trying alternative...');
        }

        // Try festival as fallback
        try {
          const tempScript = `/tmp/tts_script_${Date.now()}.txt`;
          await fs.writeFile(tempScript, text.substring(0, 500));
          execSync.execSync(`text2wave "${tempScript}" -o "${outputPath.replace('.mp3', '.wav')}"`, { stdio: 'pipe' });

          // Convert to mp3 if possible
          try {
            execSync.execSync(`ffmpeg -i "${outputPath.replace('.mp3', '.wav')}" "${outputPath}" -y`, { stdio: 'pipe' });
            execSync.execSync(`rm "${outputPath.replace('.mp3', '.wav')}"`, { stdio: 'pipe' });
          } catch {
            execSync.execSync(`mv "${outputPath.replace('.mp3', '.wav')}" "${outputPath}"`, { stdio: 'pipe' });
          }

          execSync.execSync(`rm "${tempScript}"`, { stdio: 'pipe' });
          console.log(`üì± Festival TTS audio created: ${outputPath}`);
          return outputPath;
        } catch (festivalError) {
          console.warn('festival not available either');
        }

      } catch (systemError) {
        console.warn('System TTS commands failed:', systemError.message);
      }

      // Final fallback: create a simple silence audio file with text embedded as metadata
      const { execSync } = await import('child_process');
      try {
        // Create 10 seconds of silence as final fallback
        execSync.execSync(`ffmpeg -f lavfi -i "anullsrc=channel_layout=stereo:sample_rate=22050" -t 10 "${outputPath}" -y`, { stdio: 'pipe' });
        console.log(`üîá Created silence audio as final fallback: ${outputPath}`);
        return outputPath;
      } catch {
        // If even ffmpeg fails, create a minimal audio-like file
        const minimalAudioHeader = Buffer.from([
          0x49, 0x44, 0x33, 0x04, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // ID3 header
          0xFF, 0xFB, 0x90, 0x00  // MP3 frame header
        ]);
        await fs.writeFile(outputPath, minimalAudioHeader);
        console.log(`üì± Created minimal audio file: ${outputPath}`);
        return outputPath;
      }

    } catch (error) {
      console.error('‚ùå Fallback audio generation failed:', error);
      throw new Error(`Fallback TTS generation failed: ${error.message}`);
    }
  }

  async generateNarration(script: string, outputDir: string, videoId: string): Promise<string> {
    const outputPath = path.join(outputDir, `${videoId}_narration.mp3`);

    // Split long scripts into chunks for better synthesis
    const chunks = this.splitTextIntoChunks(script, 4000); // Google TTS has character limits
    const audioFiles: string[] = [];

    for (let i = 0; i < chunks.length; i++) {
      const chunkPath = path.join(outputDir, `${videoId}_chunk_${i}.mp3`);
      await this.generateSpeech({
        text: chunks[i],
        outputPath: chunkPath,
        voice: 'en-IN-Wavenet-D', // Male Indian English voice
        speed: 1.1, // Slightly faster for engagement
        pitch: 0
      });
      audioFiles.push(chunkPath);
    }

    // If multiple chunks, we would need to combine them (requires ffmpeg)
    // For now, return the first chunk or implement audio concatenation
    if (audioFiles.length === 1) {
      await fs.rename(audioFiles[0], outputPath);
      return outputPath;
    } else {
      // TODO: Implement audio concatenation using ffmpeg
      // For now, just use the first chunk
      await fs.rename(audioFiles[0], outputPath);

      // Clean up remaining chunks
      for (let i = 1; i < audioFiles.length; i++) {
        await fs.unlink(audioFiles[i]).catch(() => {});
      }

      return outputPath;
    }
  }

  private splitTextIntoChunks(text: string, maxLength: number): string[] {
    const sentences = text.split(/[.!?]+/).filter(s => s.trim().length > 0);
    const chunks: string[] = [];
    let currentChunk = '';

    for (const sentence of sentences) {
      const trimmedSentence = sentence.trim();
      if (currentChunk.length + trimmedSentence.length + 1 <= maxLength) {
        currentChunk += (currentChunk ? '. ' : '') + trimmedSentence;
      } else {
        if (currentChunk) {
          chunks.push(currentChunk + '.');
        }
        currentChunk = trimmedSentence;
      }
    }

    if (currentChunk) {
      chunks.push(currentChunk + '.');
    }

    return chunks.length > 0 ? chunks : [text];
  }

  getAvailableVoices() {
    return {
      'en-IN-Standard-A': 'Indian English Female',
      'en-IN-Standard-B': 'Indian English Male',
      'en-IN-Standard-C': 'Indian English Female',
      'en-IN-Standard-D': 'Indian English Male',
      'en-IN-Wavenet-A': 'Indian English Female (Premium)',
      'en-IN-Wavenet-B': 'Indian English Male (Premium)',
      'en-IN-Wavenet-C': 'Indian English Female (Premium)',
      'en-IN-Wavenet-D': 'Indian English Male (Premium)',
      'en-IN-Neural2-A': 'Indian English Female (Neural)',
      'en-IN-Neural2-B': 'Indian English Male (Neural)',
      'en-IN-Neural2-C': 'Indian English Female (Neural)',
      'en-IN-Neural2-D': 'Indian English Male (Neural)',
    };
  }
}

export const textToSpeechService = new TextToSpeechService();